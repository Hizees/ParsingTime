
\Section{intro}{Introduction}
% -- Temporal Comparison
%(intro to systems)
Temporal resolution is a well-studied area, with a number of successful systems
	implemented.
We compare against \sys{HeidelTime} \cite{key:2010strotgen-temporal}
	entered into the \dataset{TempEval-2} task \cite{key:2010verhagen-tempeval},
	although other rule based systems (
		\newcite{key:2010grover-temporal}, 	\newcite{key:2010uzzaman-temporal},
		\newcite{key:2000mani-temporal}, \textit{inter alia}
	) are worth noting.

%(segue into approach)
Diverging from the rule-based approaches to temporal resolution,
	we explore employing distantly supervised probabilistic parsing
	to learn to parse these expressions.

% -- Approach
%(ambiguity)
Employing probabilistic techniques allows us to capture ambiguity in temporal 
	phrases in two important respects.
In part, it captures syntactic ambiguity -- as in \tp{last Friday
	the \th{13}} referring to either the previous \te{Friday} or the previous
	\te{Friday the \th{13}}.
In addition, temporal expressions often carry a pragmatic ambiguity.
For instance, a speaker may refer to either the next of previous Friday
	when he utters \tp{Friday} on a Sunday.
Furthermore, probabilistic systems in general allow proagation of uncertainty
	to higher-level components -- for example recognizing that \tp{May} could
	refer to both a month or a person and allowing a system with a broader
	contextual scope to make a concrete judgement.

%(compositional)
Our approach assumes that temporal phrases -- such as \tp{Last Friday} -- have
	associated with them not only a grounded time (the date of the previous
	Friday), but also a latent semantic parse.
This would assign a meaning to the terms \tp{last} and \tp{Friday}; the
	meaning of the compound phrase would then be a compositional combination
	of the two components.
We describe this representation in depth in \refsec{repr}.

%(distant supervision)
In this sense, the task can be framed as a distantly supervised parsing
	problem (\refsec{learn}).
Given an input phrase and the constraint that the parse must resolve 
	(\textit{ground}) to the
	given gold time, the system learns the parameters of a latent parse during
	training, and infers both the parse and its grounding at evaluation time.

%%(algorithm)
%Such a compositional grammar is developed, and an EM-esque algorithm is
%	employed to infer latent parses and learn the relevant parameters for
%	the grammar.

% -- Semantic Parsing Comparison
This approach draws inspiration from a large body of work
	on parsing expressions into a logical form.
Rather than employing first-order logic; however,
	we instead define a custom compositional representation of temporal
	concepts, and parse into that representation.
Like first-order logic, the representation is compositional, and can be
	evaluated to produce grounded temporal expressions
	-- with a \textit{reference time} taking the place of a database 
	of facts.

%(supervised)
Supervised approaches to the task prominently include
	\newcite{key:1996zelle-semantics},
	\newcite{key:2005zettlemoyer-semantics},
	\newcite{key:2007zettlemoyer-semantics}, 
	\textit{inter alia}.
We build upon these by loosening the supervision on the parses.
Notably, the annotation for temporal expressions does not imply any information
	about the terms within the parse; therefore the parse must be constructed
	without any cues hinting at its constituents.
To demonstrate, consider that we may describe the date of \tp{a week ago today}
	using the completely different terms \tp{week ago} or \tp{last [today's day
	of the week]} or the cannonical \tp{[month] [day]} form.
\textit{A priori} each of these examples appear as similar two-word
	temporal phrases.

%(distantly supervised)
Recent work by \newcite{key:2011liang-semantics} and 
	\newcite{key:2010clarke-semantics} similarly relax supervision 
	to require only annotated answers rather than annotated logical forms.
The presented system operates under a similar distantly-supervised framework,
	with grounded dates acting as annotated answers.
The temporal domain however, unlike the \dataset{GeoQueries} and \dataset{Jobs}
	datasets used in these works, has a more unconstrained output space.
The equivalent of a database of temporal expressions is the
	unbounded set of possible periods of time and dates / times.
In addition, we  make use of no intelligent
	initialization to assist the bootstrapping process.

%(table of contents)
We describe the \textit{logic} of time -- our temporal representation
	(\refsec{repr}), followed by the distantly supervised learning algorithm
	(\refsec{learn}); we conclude with experimental results 
	(\refsec{result}) showing our
	approach to be competitive with state of the art systems.
